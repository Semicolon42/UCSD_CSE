{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "import nltk;\n",
    "# nltk.download()\n",
    "\n",
    "def done():\n",
    "    print \"\\n===DONE===\"\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Brown Words:  <class 'nltk.corpus.reader.util.ConcatenatedCorpusView'> 1161192 \n",
      "\n",
      "====STOP WORDS====\n",
      "set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', u\"wasn't\", u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", u'below', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', u\"aren't\", u'by', u'on', u'about', u'couldn', u'of', u\"wouldn't\", u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u\"didn't\", u'but', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u\"weren't\", u'these', u'up', u'will', u'while', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once'])\n",
      "\n",
      "Regex Pattern Requirement: (.*)[a-zA-Z]+(.*)\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# ==== The Words ====\n",
    "brown_words = nltk.corpus.brown.words();\n",
    "print \"Corpus Brown Words: \", type(brown_words), len(brown_words), \"\\n\"\n",
    "\n",
    "# ==== STOP WORDS ====\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print \"====STOP WORDS====\\n\",stop_words\n",
    "\n",
    "# ==== MUST CONTAIN AN ALPHABET CHARACTER ====\n",
    "regex = \"(.*)[a-zA-Z]+(.*)\"\n",
    "regex_pattern = re.compile(regex)\n",
    "print \"\\nRegex Pattern Requirement: \" + regex\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag-Of-Words Count 47892\n",
      "\n",
      "Unfilteres Words: 1161192 Filtered: 530090\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "debug = False\n",
    "\n",
    "# Initialize Word Counts\n",
    "wc = dict()\n",
    "words = []\n",
    "\n",
    "#Building Word Counts\n",
    "j = 0\n",
    "s = \"\"\n",
    "for i in range(len(brown_words)):\n",
    "    w = brown_words[i].lower()\n",
    "    if w not in stop_words and regex_pattern.match(w):\n",
    "        words.append(w)\n",
    "        wc[w] = wc.get(w, 0) + 1\n",
    "        \n",
    "        if debug:\n",
    "            j+=1\n",
    "            s = s + \" \" + w\n",
    "            if j > 100:\n",
    "                print s\n",
    "                s = \"\"\n",
    "                j=0\n",
    "\n",
    "swc = []\n",
    "for key, value in sorted(wc.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    swc.append([key, value])\n",
    "                \n",
    "print \"\\nBag-Of-Words size\", len(swc), \", Top 10: \", swc[:10]\n",
    "print \"\\nUnfilteres Words:\",len(brown_words),\"Filtered:\",len(words)\n",
    "\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Words  5000 , Top 10:  [u'one', u'would', u'said', u'new', u'could', u'time', u'two', u'may', u'first', u'like']\n",
      "\n",
      "Context Words  1000 , Top 10:  [[u'one', 3292], [u'would', 2714], [u'said', 1961], [u'new', 1635], [u'could', 1601], [u'time', 1598], [u'two', 1412], [u'may', 1402], [u'first', 1361], [u'like', 1292]]\n",
      "Context Words  1000 , Top 10:  [u'one', u'would', u'said', u'new', u'could', u'time', u'two', u'may', u'first', u'like']\n",
      "Context index_map  1000 one <type 'unicode'>\n",
      "\n",
      "Word Window [None, None, None, u'fulton', u'county'] None [0, 1, 3, 4] [0, 1, 3, 4]\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == Getting Vocab sets\n",
    "# == \n",
    "\n",
    "vocabulary_size = 5000\n",
    "V = swc[:vocabulary_size]\n",
    "V_words = []; \n",
    "for v in V: \n",
    "    V_words.append(v[0])\n",
    "print \"Vocabulary Words \", len(V_words), \", Top 10: \", V_words[:10]\n",
    "\n",
    "context_size = 1000\n",
    "\n",
    "C = swc[:context_size]\n",
    "C_words = []\n",
    "for c in C:\n",
    "    C_words.append(c[0])\n",
    "print \"\\nContext Words \", len(C), \", Top 10: \", C[:10]\n",
    "print \"Context Words \", len(C_words), \", Top 10: \", C_words[:10]\n",
    "\n",
    "C_index_map = dict()\n",
    "for i in range(len(C_words)):\n",
    "    C_index_map[C_words[i]] = i\n",
    "print \"Context index_map \", len(C_index_map), C_words[0], type(C_words[0])\n",
    "\n",
    "\n",
    "window = 2\n",
    "word_window_words = [None]*(len(words)+window*2)\n",
    "word_window_words[window:-window] = words\n",
    "word_window = [None]*(window+window+1)\n",
    "word_window[(window+1):] = words[:window]\n",
    "window_range = range(window+window+1)\n",
    "del window_range[window]\n",
    "print \"\\nWord Window\", word_window, word_window[window], window_range[:5], window_range[-5:]\n",
    "\n",
    "\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEST> one <type 'unicode'> <_sre.SRE_Match object at 0x112944c68>\n",
      "<TEST> . <type 'unicode'> None\n",
      "Time: 0.905466079712\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# Test bed\n",
    "temp = u'one'\n",
    "print \"<TEST>\", temp, type(temp), regex_pattern.match(temp)\n",
    "temp = u'.'\n",
    "print \"<TEST>\", temp, type(temp), regex_pattern.match(temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10000000):\n",
    "    j=i\n",
    "\n",
    "stop = timeit.default_timer()\n",
    "print \"Time:\",stop - start \n",
    "\n",
    "\n",
    "m = 50.\n",
    "i = 0.\n",
    "while i < m:\n",
    "    i+=1\n",
    "    f.value = i/m * 100\n",
    "    \n",
    "    \n",
    "\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: <type 'list'> <type 'list'> [[u'one', 3292], [u'would', 2714], [u'said', 1961], [u'new', 1635], [u'could', 1601]]\n",
      "Word Context: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317f80ee854543f09fd1468b7dca6b55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>FloatProgress</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "FloatProgress(value=0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: 1520835429.87\n",
      "Stop: 1520836014.47\n",
      "Time: 584.601584911\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "import timeit\n",
    "\n",
    "\n",
    "print \"C:\", type(C),type(C[0]),C[:5]\n",
    "word_context = {\"word\":[]}\n",
    "print \"Word Context:\",len(word_context)\n",
    "\n",
    "words_length = len(words)\n",
    "f = FloatProgress(min=0, max=100)\n",
    "display(f)\n",
    "\n",
    "start = timeit.default_timer()\n",
    "print \"Start:\",start\n",
    "# for index in range(2000):\n",
    "for index in range(words_length):\n",
    "    f.value = index / float(words_length)*100\n",
    "    word = words[index]\n",
    "    if word not in V_words:\n",
    "        continue;\n",
    "    word_window = word_window_words[index:index+window+window+1];\n",
    "    word_context[word] = [0]*len(C_words)\n",
    "    for i in window_range:\n",
    "        if word_window[i] in C_words:\n",
    "            cw = word_window[i]\n",
    "            word_context[word][C_index_map[cw]] += 1\n",
    "            if DEBUG and sum(word_context[word]) > 1:\n",
    "                print word,cw,word_context[word][C_index_map[cw]],sum(word_context[word])\n",
    "#             if word == cw:\n",
    "#                 print word_window\n",
    "stop = timeit.default_timer()\n",
    "print \"Stop:\",stop\n",
    "print \"Time:\",stop - start \n",
    "\n",
    "done() # ============================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5000 [u'limited', u'fig.', u'magnetic', u'child', u'dynamic'] [0, 1, 1, 4, 1]\n",
      "5000 [[u'zero', 4], [u'youngsters', 4], [u'works', 4], [u\"women's\", 4], [u'women', 4]]\n",
      "\n",
      "===DONE===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print len(word_context), word_context.keys()[:5],[sum(li) for li in word_context.values()[:5]]\n",
    "sorted_word_context = []\n",
    "for key, value in sorted(word_context.iteritems(), key=lambda (k,v): (sum(v),k), reverse=True):\n",
    "    sorted_word_context.append([key, sum(value),value])\n",
    "\n",
    "print len(sorted_word_context),[row[0:2] for row in sorted_word_context[:5]]\n",
    "\n",
    "done() # ============================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
