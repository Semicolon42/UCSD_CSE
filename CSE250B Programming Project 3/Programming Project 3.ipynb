{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n",
      "===Done===\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "import nltk;\n",
    "nltk.download()\n",
    "print \"===Done===\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus Brown Words:  <class 'nltk.corpus.reader.util.ConcatenatedCorpusView'> 1161192 \n",
      "\n",
      "====STOP WORDS====\n",
      "set([u'all', u'just', u\"don't\", u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'don', u'hadn', u'herself', u'll', u'had', u'should', u'to', u'only', u'won', u'under', u'ours', u'has', u\"should've\", u\"haven't\", u'do', u'them', u'his', u'very', u\"you've\", u'they', u'not', u'during', u'now', u'him', u'nor', u\"wasn't\", u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u\"won't\", u'where', u\"mustn't\", u\"isn't\", u'few', u'because', u\"you'd\", u'doing', u'some', u'hasn', u\"hasn't\", u'are', u'our', u'ourselves', u'out', u'what', u'for', u\"needn't\", u'below', u're', u'does', u\"shouldn't\", u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u\"mightn't\", u\"doesn't\", u'were', u'here', u'shouldn', u'hers', u\"aren't\", u'by', u'on', u'about', u'couldn', u'of', u\"wouldn't\", u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u\"hadn't\", u'mightn', u\"couldn't\", u'wasn', u'your', u\"you're\", u'from', u'her', u'their', u'aren', u\"it's\", u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u\"didn't\", u'but', u\"that'll\", u'with', u'than', u'those', u'he', u'me', u'myself', u'ma', u\"weren't\", u'these', u'up', u'will', u'while', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u\"shan't\", u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u\"you'll\", u'so', u'y', u\"she's\", u'the', u'having', u'once'])\n",
      "Regex Pattern Requirement: (.*)[a-zA-Z]+(.*)\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "\n",
    "# ==== The Words ====\n",
    "brown_words = nltk.corpus.brown.words();\n",
    "print \"Corpus Brown Words: \", type(brown_words), len(brown_words), \"\\n\"\n",
    "\n",
    "# ==== STOP WORDS ====\n",
    "stop_words = set(stopwords.words('english'))\n",
    "print \"====STOP WORDS====\\n\",stop_words\n",
    "\n",
    "# ==== MUST CONTAIN AN ALPHABET CHARACTER ====\n",
    "regex_pattern = \"(.*)[a-zA-Z]+(.*)\"\n",
    "p = re.compile(regex_pattern)\n",
    "print \"Regex Pattern Requirement: \" + regex_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bag-Of-Words Count 47892\n",
      "\n",
      "Unfilteres Words: 1161192 Filtered: 530090\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "debug = False\n",
    "\n",
    "# Initialize Word Counts\n",
    "wc = dict()\n",
    "words = []\n",
    "\n",
    "#Building Word Counts\n",
    "j = 0\n",
    "s = \"\"\n",
    "for i in range(len(brown_words)):\n",
    "    w = brown_words[i].lower()\n",
    "    if w not in stop_words and p.match(w):\n",
    "        words.append(w)\n",
    "        wc[w] = wc.get(w, 0) + 1\n",
    "        \n",
    "        if debug:\n",
    "            j+=1\n",
    "            s = s + \" \" + w\n",
    "            if j > 100:\n",
    "                print s\n",
    "                s = \"\"\n",
    "                j=0\n",
    "\n",
    "print \"\\nBag-Of-Words Count\", len(wc)\n",
    "print \"\\nUnfilteres Words:\",len(brown_words),\"Filtered:\",len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Words  5000 , Top 10:  [[u'one', 3292], [u'would', 2714], [u'said', 1961], [u'new', 1635], [u'could', 1601], [u'time', 1598], [u'two', 1412], [u'may', 1402], [u'first', 1361], [u'like', 1292]]\n",
      "\n",
      "Context Words  1000 , Top 10:  [[u'one', 3292], [u'would', 2714], [u'said', 1961], [u'new', 1635], [u'could', 1601], [u'time', 1598], [u'two', 1412], [u'may', 1402], [u'first', 1361], [u'like', 1292]]\n",
      "\n",
      "Context Words  1000 , Top 10:  [u'one', u'would', u'said', u'new', u'could', u'time', u'two', u'may', u'first', u'like']\n"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == Getting Vocab sets\n",
    "# == \n",
    "swc = []\n",
    "for key, value in sorted(wc.iteritems(), key=lambda (k,v): (v,k), reverse=True):\n",
    "    swc.append([key, value])\n",
    "\n",
    "vocabulary_size = 5000\n",
    "V = swc[:vocabulary_size]\n",
    "print \"Vocabulary Words \", len(V), \", Top 10: \", V[:10]\n",
    "\n",
    "context_size = 1000\n",
    "C = swc[:context_size]\n",
    "C_words = []\n",
    "for c in C:\n",
    "    C_words.append(c[0])\n",
    "print \"\\nContext Words \", len(C), \", Top 10: \", C[:10]\n",
    "print \"\\nContext Words \", len(C_words), \", Top 10: \", C_words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: <type 'list'> <type 'list'> [[u'said', 20], [u'jury', 18], [u'fulton', 14], [u'county', 13], [u'state', 12]]\n",
      "Word Context: 1\n",
      "Word Window [None, None, None, u'fulton', u'county'] None [0, 1, 3, 4]\n",
      "Window [None, None, None, u'fulton', u'county']\n",
      "Window [None, None, u'fulton', u'county', 'Hello']\n",
      "Window [None, u'fulton', u'county', 'Hello', 'World']\n",
      "Window [u'fulton', u'county', 'Hello', 'World', 'Kill']\n",
      "Window [u'county', 'Hello', 'World', 'Kill', 'Me']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-14da0af9d03d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mword_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mww\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_window\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mword_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mww\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mww\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "# == \n",
    "# == \n",
    "# == \n",
    "print \"C:\", type(C),type(C[0]),C[:5]\n",
    "word_context = {\"word\":[]}\n",
    "print \"Word Context:\",len(word_context)\n",
    "\n",
    "window = 2\n",
    "word_window = [None]*(window+window+1)\n",
    "word_window[(window+1):] = words[:window]\n",
    "window_range = range(window+window+1)\n",
    "del window_range[window]\n",
    "print \"Word Window\", word_window, word_window[window], window_range\n",
    "\n",
    "print \"Window\",word_window\n",
    "word_window[:-1] = word_window[1:]; word_window[-1]=\"Hello\"\n",
    "print \"Window\",word_window\n",
    "word_window[:-1] = word_window[1:]; word_window[-1]=\"World\"\n",
    "print \"Window\",word_window\n",
    "word_window[:-1] = word_window[1:]; word_window[-1]=\"Kill\"\n",
    "print \"Window\",word_window\n",
    "word_window[:-1] = word_window[1:]; word_window[-1]=\"Me\"\n",
    "print \"Window\",word_window\n",
    "\n",
    "\n",
    "for w in words:\n",
    "    word_context[w] = word_context.get(w, {})\n",
    "    for i in window_range:\n",
    "        if word_window[i] != None:\n",
    "            ww = word_window[i]\n",
    "            word_context[w][ww] = word_context[w].get(ww,0)+1\n",
    "    # Shift the window to the next word\n",
    "    word_window[:-1] = word_window[1:]; word_window[-1]=w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
